cat("ERROR: Models 80 and 81 require between 3 and 6 mediators. \n")}
if (errcode[i,1]==33)
{cat(" \n")
cat("ERROR: Model 82 requires 4 mediators. \n")}
if (errcode[i,1]==34)
{cat(" \n")
cat("ERROR: This model number requires between 2 and 6 mediators. \n")}
if (errcode[i,1]==35)
{cat(" \n")
cat("ERROR: In a model with only one moderator, that moderator must be W. \n")}
if (errcode[i,1]==36)
{cat(" \n")
cat("ERROR: A serial mediation model cannot have more than 6 mediators. \n")}
if (errcode[i,1]==37)
{cat(" \n")
cat("ERROR: No more than 10 mediators are allowed in a PROCESS command. \n")}
if (errcode[i,1]==38)
{cat(" \n")
cat("ERROR: XCATCODE is not provided, not the correct length, or is otherwise invalid. \n")}
if (errcode[i,1]==39)
{cat(" \n")
cat("ERROR: WCATCODE is not provided, not the correct length, or is otherwise invalid. \n")}
if (errcode[i,1]==40)
{cat(" \n")
cat("ERROR: ZCATCODE is not provided, not the correct length, or is otherwise invalid. \n")}
if (errcode[i,1]==41)
{cat(" \n")
cat("ERROR: Models 1, 2, and 3 cannot be customized. \n")}
if (errcode[i,1]==43)
{cat(" \n")
cat("ERROR: PROCESS does not allow dichotomous mediators. \n")}
if (errcode[i,1]==50)
{cat(" \n")
cat("ERROR: A multicategorical moderator cannot be specified as a covariate. \n")}
if (errcode[i,1]==51)
{cat(" \n")
cat("ERROR: A variable you specified as a covariate is a moderator in all equations. \n")}
if (errcode[i,1]==62)
{cat(" \n")
cat("ERROR: After listwise deletion of cases with missing data, too few cases remain. \n")}
if (errcode[i,1]==63)
{cat(" \n")
cat("ERROR: The XMINT option is available only for model 4. \n")}
if (errcode[i,1]==64)
{cat(" \n")
cat("ERROR: Incorrect number of values specified in CDEVAL option. \n")}
if (errcode[i,1]==65)
{cat(" \n")
cat("ERROR: Only indicator or sequential coding of X is allowed with the XMINT option. \n")}
if (errcode[i,1]==66)
{cat(" \n")
cat("ERROR: A reference value of X is required for this model. \n")}
if (errcode[i,1]==67)
{cat(" \n")
cat("ERROR: Too many elements provided in XREFVAL option. \n")}
if (errcode[i,1]==68)
{cat(" \n")
cat("ERROR: Covariate assignment is not allowed with the XMINT option. \n")}
if (errcode[i,1]==69)
{cat(" \n")
cat("ERROR: Incorrect number of values specified in COVAL option. \n")}
if (errcode[i,1]==70)
{cat(" \n")
cat("ERROR: Incorrect value(s) in XREFVAL for this dichotomous X variable. \n")}
if (errcode[i,1]==71)
{cat(" \n")
cat("ERROR: The CENTER option is not available when using the XMINT option. \n")}
if (errcode[i,1]==72)
{cat(" \n")
cat("ERROR: The XMINT option is not available for models with a dichotomous Y. \n")}
if ((errcode[i,1]==52) & (mcerpt==0))
{mcerpt<-1
cat(" \n")
cat("ERROR: A variable specified as multicategorical must have at least three categories. \n")}
if (errcode[i,1]==53)
{cat(" \n")
cat("ERROR: Variables declared as factors or that are non-numeric are not accepted by PROCESS.\n")}
}
#if (saveboot==1)
#{resultm<-list(resultm,boots)}
#invisible(resultm)
resultms<-NULL
if ((saveboot==0) & (saveest==1)){resultms<-resultm}
if ((saveboot==1) & (saveest==0)){resultms<-boots}
if ((saveboot==1) & (saveest==1)){resultms<-(list(boots,resultm))}
invisible(resultms)
}
process(activate=1)
data_mediation <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]
data_mediation$mean_stress <- rowMeans(data_mediation[,grep("stress_week[1-7]", names(data_mediation))], na.rm = TRUE)
data_mediation$mean_motivation <- rowMeans(data_mediation[,grep("motivation_week[1-7]", names(data_mediation))], na.rm = TRUE)
grep("stress_week[1-7]", names(data_mediation))
data_wide <- read.csv("./data/data_wide.csv", na.strings = c("NA", ""))
data_long <- read.csv("./data/data_long.csv", na.strings = c("NA", ""))
data_wide$overall_mark <- (data_wide$midtermgrade_total_mark + data_wide$endtermgrade_total_mark) / 2
data_wide$adhd_binary <- ifelse(data_wide$adhd_diagnosis == "No ADHD", 0, 1)
data_wide$gender_binary <- ifelse(data_wide$gender == "Woman", 0,
ifelse(data_wide$gender == "Man", 1, NA))
# ASRS-6 diagnosis
data_wide$asrs_diagnosis <- with(data_wide, ((adhd_1 >= 3) + (adhd_2 >= 3) + (adhd_3 >= 3) + (adhd_4 >= 4) + (adhd_5 >= 4) + (adhd_6 >= 4)) >= 4)
data_wide$asrs_diagnosis <- as.integer(data_wide$asrs_diagnosis)
data_wide$sum_time_reading <- rowSums(data_wide[, c("time_reading_week1", "time_reading_week2", "time_reading_week3", "time_reading_week4", "time_reading_week5", "time_reading_week6", "time_reading_week7")], na.rm = TRUE)
data_wide$mean_time_reading <- rowMeans(data_wide[, c("time_reading_week1", "time_reading_week2", "time_reading_week3", "time_reading_week4", "time_reading_week5", "time_reading_week6", "time_reading_week7")], na.rm = TRUE)
data_wide$sum_time_listening <- rowSums(data_wide[, c("time_listening_week1", "time_listening_week2", "time_listening_week3", "time_listening_week4", "time_listening_week5", "time_listening_week6", "time_listening_week7")], na.rm = TRUE)
data_wide$mean_time_listening <- rowMeans(data_wide[, c("time_listening_week1", "time_listening_week2", "time_listening_week3", "time_listening_week4", "time_listening_week5", "time_listening_week6", "time_listening_week7")], na.rm = TRUE)
data_wide$mean_motivation <- rowMeans(data_wide[, c("motivation_week1", "motivation_week2", "motivation_week3", "motivation_week4", "motivation_week5", "motivation_week6", "motivation_week7")], na.rm = TRUE)
data_long$overall_mark <- data_wide$overall_mark[match(data_long$tid, data_wide$tid)]
data_long$sum_time_listening <- data_wide$sum_time_listening[match(data_long$tid, data_wide$tid)]
data_long$condition_binary <- as.factor(data_long$condition_binary)
data_long$asrs_diagnosis <- data_wide$asrs_diagnosis[match(data_long$tid, data_wide$tid)]
data_long$adhd_binary <- ifelse(data_long$adhd_diagnosis == "No ADHD", 0, 1)
library(lavaan)
model <- '
inattention =~ adhd_1 + adhd_2 + adhd_3 + adhd_4
hyperactivity =~ adhd_5 + adhd_6
inattention ~~ hyperactivity
'
# Results show adequate model fit
fit <- cfa(model, data = data_wide)
summary(fit, standardized = TRUE, fit.measures = TRUE)
latent_scores <- lavPredict(fit, type = "lv")
# Add factor scores to the dataset
data_wide$inattention[!is.na(data_wide$adhd_1)] <- latent_scores[, "inattention"]
data_wide$hyperactivity[!is.na(data_wide$adhd_1)] <- latent_scores[, "hyperactivity"]
data_long$inattention <- data_wide$inattention[match(data_long$tid, data_wide$tid)]
data_long$hyperactivity <- data_wide$hyperactivity[match(data_long$tid, data_wide$tid)]
# Compare to calculated scale scores
plot(data_wide$adhd_inattention, data_wide$inattention)
plot(data_wide$adhd_hyperactivity, data_wide$hyperactivity)
data_mediation <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]
data_mediation$mean_stress <- rowMeans(data_mediation[,grep("stress_week[1-7]", names(data_mediation))], na.rm = TRUE)
data_mediation$mean_motivation <- rowMeans(data_mediation[,grep("motivation_week[1-7]", names(data_mediation))], na.rm = TRUE)
process(data = data_mediation, y = "overall_mark", x = "condition_binary", m = c("mean_motivation", "mean_time_reading"), stand =1, effsize =1, model = 6, total =1)
subset_data <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]
boot_function <- function(data, indices) {
d <- data[indices,]
fit <- lm(overall_mark ~ condition_binary * hyperactivity, data = d)
return(coef(fit))
}
set.seed(1)
results <- boot(data = subset_data, statistic = boot_function, R = 5000)
results
boot.ci(results_hyper, type = "bca", index = 2)
subset_hyper <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]
boot_hyper <- function(data, indices) {
d <- data[indices,]
fit <- lm(overall_mark ~ condition_binary * hyperactivity, data = d)
return(coef(fit))
}
set.seed(1)
results_hyper <- boot(data = subset_hyper, statistic = boot_hyper, R = 5000)
boot.ci(results_hyper, type = "bca", index = 2)
boot.ci(results_hyper, type = "bca", index = 3)
boot.ci(results_hyper, type = "bca", index = 4)
citation()
table(data_wide$firsttimecourse)
hist(data_wide$age, breaks = 20)
data_wide[data_wide$age == 1818, "age"] <- 18 #fix incorrect value
hist(data_wide$age, breaks = 20)
psych::describe(data_wide$age)
#Homoscedasticity
plot(lm(overall_mark ~ inattention, data = data_wide))
plot(lm(overall_mark ~ hyperactivity, data = data_wide))
#Linearity
plot(data_wide$inattention, residuals(lm(overall_mark ~ inattention, data = data_wide)))
#Linearity
plot(data_wide$inattention, data_wide$overall_mark)
plot(data_wide$hyperactivity, data_wide$overall_mark)
#Linearity
plot(data_wide$inattention, data_wide$overall_mark)
abline(lm(overall_mark ~ inattention, data = data_wide))
plot(data_wide$inattention, data_wide$overall_mark)
abline(lm(overall_mark ~ inattention, data = data_wide))
plot(data_wide$hyperactivity, data_wide$overall_mark)
abline(lm(overall_mark ~ hyperactivity, data = data_wide))
plot(data_wide$inattention, data_wide$overall_mark)
loess_fit <- loess.smooth(data_wide$inattention, data_wide$overall_mark)
lines(loess_fit$x, loess_fit$y, col="red")  # Change 'col' as needed
plot(data_wide$hyperactivity, data_wide$overall_mark)
loess_fit <- loess.smooth(data_wide$hyperactivity, data_wide$overall_mark)
lines(loess_fit$x, loess_fit$y, col="red")
vif(lm(overall_mark ~ inattention + hyperactivity, data = data_wide))
#Multicollinearity with VIF
car::vif(lm(overall_mark ~ inattention + hyperactivity, data = data_wide))
#Mahalanobis distance
mahalanobis(lm(overall_mark ~ inattention, data = data_wide))
#Mahalanobis distance
vars <- data_wide[, c("overall_mark", "inattention",)]
#Mahalanobis distance
vars <- data_wide[, c("overall_mark", "inattention")]
mahalanobis(vars, center = colMeans(vars, na.rm = T), cov = cov(vars, use = "pairwise.complete.obs"))
data_inatt <- data_wide[!is.na(data_wide$inattention) & !is.na(data_wide$overall_mark),]
data_hyper <- data_wide[!is.na(data_wide$hyperactivity) & !is.na(data_wide$overall_mark),]
data_inatt <- data_wide[!is.na(data_wide$inattention) & !is.na(data_wide$overall_mark),]
data_hyper <- data_wide[!is.na(data_wide$hyperactivity) & !is.na(data_wide$overall_mark),]
#Mahalanobis distance
vars <- data_inatt[, c("overall_mark", "inattention")]
mah_inatt <- mahalanobis(vars, center = colMeans(vars, na.rm = T), cov = cov(vars, use = "pairwise.complete.obs"))
threshold <- qchisq(0.95, df = 2)
vars <- data_hyper[, c("overall_mark", "hyperactivity")]
mah_hyper <- mahalanobis(vars, center = colMeans(vars, na.rm = T), cov = cov(vars, use = "pairwise.complete.obs"))
#Cooks distance
cook_inatt <- cooks.distance(lm(overall_mark ~ inattention, data = data_inatt))
cook_treshold_inatt <- 3 * mean(cook_inatt, na.rm = T)
cook_hyper <- cooks.distance(lm(overall_mark ~ hyperactivity, data = data_hyper))
cook_treshold_hyper <- 3 * mean(cook_hyper, na.rm = T)
#Repeat analyses without outliers and influential points
data_inatt <- data_wide[mah_inatt < threshold & cook_inatt < cook_treshold_inatt,]
summary(lm(overall_mark ~ inattention, data = data_inatt))
data_hyper <- data_wide[mah_hyper < threshold & cook_hyper < cook_treshold_hyper,]
summary(lm(overall_mark ~ hyperactivity, data = data_hyper))
## Inattention negatively predicts grade
summary(lm(overall_mark ~ inattention, data = data_wide))
## Hyperactivity negatively predicts grade
summary(lm(overall_mark ~ hyperactivity, data = data_wide))
#Homoscedasticity and normality
plot(lm(overall_mark ~ inattention, data = data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]))
#Homoscedasticity and normality
data_inatt_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$inattention) & !is.na(data_wide$overall_mark),]
plot(lm(overall_mark ~ inattention, data = data_inatt_AL))
#Linearity
plot(data_inatt_AL$inattention, data_inatt_AL$overall_mark)
#Homoscedasticity and normality
data_inatt_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$inattention) & !is.na(data_wide$overall_mark),]
plot(lm(overall_mark ~ inattention, data = data_inatt_AL))
#Linearity already shown for Hypothesis Ia
#Mahalanobis distance
vars <- data_inatt_AL[, c("overall_mark", "inattention", "condition_binary")]
mah_inatt_AL <- mahalanobis(vars, center = colMeans(vars, na.rm = T), cov = cov(vars, use = "pairwise.complete.obs"))
threshold_3 <- qchisq(0.95, df = 3)
#Cooks distance
cook_inatt_AL <- cooks.distance(lm(overall_mark ~ inattention*condition_binary, data = data_inatt_AL))
cook_treshold_inatt_AL <- 3 * mean(cook_inatt, na.rm = T)
#Repeat analyses without outliers and influential points
data_inatt_AL_clean <- data_inatt_AL[mah_inatt_AL < threshold_3 & cook_inatt_AL < cook_treshold_inatt_AL,]
summary(mod_inatt_AL_clean <- lm(overall_mark ~ condition_binary + inattention, data = data_inatt_AL_clean))
summary(mod2_inatt_AL_clean <- lm(overall_mark ~ condition_binary*inattention, data = data_inatt_AL_clean))
anova(mod_inatt_AL_clean, mod2_inatt_AL_clean)
# Homoscedasticity and normality
plot(lm(overall_mark ~ condition_binary * hyperactivity, data = data_hyper_AL))
data_hyper_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$hyperactivity) & !is.na(data_wide$overall_mark),]
# Homoscedasticity and normality
plot(lm(overall_mark ~ condition_binary * hyperactivity, data = data_hyper_AL))
#Mahalanobis distances
vars_hyper_AL <- data_hyper_AL[, c("overall_mark", "hyperactivity", "condition_binary")]
mah_hyper_AL <- mahalanobis(vars_hyper_AL, center = colMeans(vars_hyper_AL, na.rm = T), cov = cov(vars_hyper_AL, use = "pairwise.complete.obs"))
data_hyper_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$hyperactivity) & !is.na(data_wide$overall_mark),]
#Homoscedasticity (not violated) and normality (slightly violated at the tails)
plot(lm(overall_mark ~ condition_binary * hyperactivity, data = data_hyper_AL))
#Linearity already shown with Hypothesis Ib
#Outliers
vars_hyper_AL <- data_hyper_AL[, c("overall_mark", "hyperactivity", "condition_binary")]
mah_hyper_AL <- mahalanobis(vars_hyper_AL, center = colMeans(vars_hyper_AL, na.rm = T), cov = cov(vars_hyper_AL, use = "pairwise.complete.obs"))
threshold_3 <- qchisq(0.95, df = 3)
#Influential points
cook_hyper_AL <- cooks.distance(lm(overall_mark ~ condition_binary*hyperactivity, data = data_hyper_AL))
cook_treshold_hyper_AL <- 3 * mean(cook_hyper_AL, na.rm = T)
#Repeat analysis without outliers and influential points
data_hyper_AL_clean <- data_hyper_AL[mah_hyper_AL < threshold_3 & cook_hyper_AL < cook_treshold_hyper_AL,]
summary(mod_hyper_clean <- lm(overall_mark ~ condition_binary+hyperactivity, data = data_hyper_AL_clean))
summary(mod2_hyper_clean <- lm(overall_mark ~ condition_binary*hyperactivity, data = data_hyper_AL_clean))
anova(mod_hyper_clean, mod2_hyper_clean)
## Treatment effects on grade depend on hyperactivity
summary(mod_hyper <- lm(overall_mark ~ condition_binary+hyperactivity,
data = data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]))
# Main result for grades
summary(mod_hyper2 <- lm(overall_mark ~ condition_binary*hyperactivity,
data = data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]))
# Interaction significantly improves model fit
anova(mod_hyper, mod_hyper2)
summary(aov(overall_mark ~ condition_binary*hyperactivity,
data = data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128),]))
summary(mod_a1 <- lm(mean_motivation ~ condition_binary, data = data_mediation))
summary(mod_a2 <- lm(mean_time_reading ~ mean_motivation + condition_binary, data = data_mediation))
summary(mod_b1 <- lm(overall_mark ~ mean_motivation + condition_binary, data = data_mediation))
summary(mod_b2 <-  lm(overall_mark ~ mean_motivation + mean_time_reading + condition_binary, data = data_mediation))
summary(mod_c_prime <- lm(overall_mark ~ condition_binary, data = data_mediation))
summary(mod_d <- lm(mean_motivation ~ mean_time_reading, data = data_mediation))
# Homoscedasticity (not violated) and normality (slightly violated at the tails)
plot(mod_a1)
plot(mod_a2)
plot(mod_b1)
plot(mod_b2)
hist(data_wide$overall_mark)
summary(mod_a1 <- lm(mean_motivation ~ condition_binary, data = data_mediation))
summary(mod_a1 <- lm(mean_motivation ~ condition_binary, data = data_mediation))
summary(mod_a2 <- lm(mean_time_reading ~ mean_motivation + condition_binary, data = data_mediation))
summary(mod_b1 <- lm(overall_mark ~ mean_motivation + condition_binary, data = data_mediation))
plot(mod_b2)
summary(mod_b2 <-  lm(overall_mark ~ mean_motivation + mean_time_reading + condition_binary, data = data_mediation))
summary(mod_c_prime <- lm(overall_mark ~ condition_binary, data = data_mediation))
summary(mod_d <- lm(mean_motivation ~ mean_time_reading, data = data_mediation))
cook_threshold <- function(col){
threshold <- 3 * mean(col, na.rm = T)
return(threshold)
}
mediation_cook <- matrix(ncol=6, nrow=nrow(data_mediation_AL))
mediation_cook[,1] <- cooks.distance(mod_a1)
mediation_cook <- matrix(ncol=6, nrow=nrow(data_mediation_AL))
data_mediation_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$overall_mark) & !is.na(data_wide$mean_motivation) & !is.na(data_wide$mean_time_reading),]
summary(mod_a1 <- lm(mean_motivation ~ condition_binary, data = data_mediation_AL))
summary(mod_a2 <- lm(mean_time_reading ~ mean_motivation + condition_binary, data = data_mediation_AL))
summary(mod_b1 <- lm(overall_mark ~ mean_motivation + condition_binary, data = data_mediation_AL))
summary(mod_b2 <-  lm(overall_mark ~ mean_motivation + mean_time_reading + condition_binary, data = data_mediation_AL))
summary(mod_c_prime <- lm(overall_mark ~ condition_binary, data = data_mediation_AL))
summary(mod_d <- lm(mean_motivation ~ mean_time_reading, data = data_mediation_AL))
mediation_cook <- matrix(ncol=6, nrow=nrow(data_mediation_AL))
mediation_cook[,1] <- cooks.distance(mod_a1)
mediation_cook[,2] <- cooks.distance(mod_a2)
mediation_cook[,3] <- cooks.distance(mod_b1)
mediation_cook[,4] <- cooks.distance(mod_b2)
mediation_cook[,5] <- cooks.distance(mod_c_prime)
mediation_cook[,6] <- cooks.distance(mod_d)
data_mediation_AL <- data_wide[(data_wide$condition_binary == 0 | data_wide$sum_time_listening >= 128) & !is.na(data_wide$overall_mark) & !is.na(data_wide$mean_motivation) & !is.na(data_wide$mean_time_reading),]
get_mah <- function(data, vars){
mah <- mahalanobis(data[,vars], center = colMeans(data[,vars], na.rm = T), cov = cov(data[,vars], use = "pairwise.complete.obs"))
return(mah)
}
mediation_mah <- matrix(ncol=6, nrow=nrow(data_mediation_AL))
mediation_mah[,1] <- get_mah(data_mediation_AL, c("mean_motivation", "condition_binary"))
mediation_mah[,2] <- get_mah(data_mediation_AL, c("mean_time_reading", "mean_motivation", "condition_binary"))
mediation_mah[,3] <- get_mah(data_mediation_AL, c("overall_mark", "mean_motivation", "condition_binary"))
mediation_mah[,4] <- get_mah(data_mediation_AL, c("overall_mark", "mean_motivation", "mean_time_reading", "condition_binary"))
mediation_mah[,5] <- get_mah(data_mediation_AL, c("overall_mark", "condition_binary"))
mediation_mah[,6] <- get_mah(data_mediation_AL, c("mean_motivation", "mean_time_reading"))
treshold_2 <- qchisq(0.95, df = 2)
threshold_3 <- qchisq(0.95, df = 3)
threshold_4 <- qchisq(0.95, df = 4)
cook_threshold <- function(col){
threshold <- 3 * mean(col, na.rm = T)
return(threshold)
}
mediation_cook <- matrix(ncol=6, nrow=nrow(data_mediation_AL))
mediation_cook[,1] <- cooks.distance(mod_a1)
mediation_cook[,2] <- cooks.distance(mod_a2)
mediation_cook[,3] <- cooks.distance(mod_b1)
mediation_cook[,4] <- cooks.distance(mod_b2)
mediation_cook[,5] <- cooks.distance(mod_c_prime)
mediation_cook[,6] <- cooks.distance(mod_d)
#Filter outliers and influential points
mah_exceeds <- apply(mediation_mah, 2, function(col) {
threshold <- switch(length(col), "2" = threshold_2, "3" = threshold_3, "4" = threshold_4)
return(col > threshold)
})
mah_exceeds_any <- apply(mah_exceeds, 1, any)
#Filter outliers and influential points
mah_exceeds <- apply(mediation_mah, 2, function(col) {
threshold <- switch(length(col), "2" = threshold_2, "3" = threshold_3, "4" = threshold_4)
return(col > threshold)
})
#Filter outliers and influential points
mah_exceeds <- matrix(FALSE, ncol=6, nrow=nrow(data_mediation_AL))  # Initialize a logical matrix
mah_exceeds[,1] <- mediation_mah[,1] > threshold_2
mah_exceeds[,2] <- mediation_mah[,2] > threshold_3
threshold_2 <- qchisq(0.95, df = 2)
mah_exceeds[,1] <- mediation_mah[,1] > threshold_2
mah_exceeds[,2] <- mediation_mah[,2] > threshold_3
mah_exceeds[,3] <- mediation_mah[,3] > threshold_3
mah_exceeds[,4] <- mediation_mah[,4] > threshold_4
mah_exceeds[,5] <- mediation_mah[,5] > threshold_3
mah_exceeds[,6] <- mediation_mah[,6] > threshold_2
mah_exceeds_any <- apply(mah_exceeds, 1, any)
cook_exceeds <- apply(mediation_cook, 2, function(col) col > cook_threshold(col))
cook_exceeds_any <- apply(cook_exceeds, 1, any)
exclude <- mah_exceeds_any | cook_exceeds_any
sum(exclude)
data_mediation_AL_filtered <- data_mediation_AL[!exclude, ]
process(data = data_mediation_AL_filtered, y = "overall_mark", x = "condition_binary", m = c("mean_motivation", "mean_time_reading"), stand =1, effsize =1, model = 6, total =1)
process(data = data_mediation, y = "overall_mark", x = "condition_binary", m = c("mean_motivation", "mean_time_reading"), stand =1, effsize =1, model = 6, total =1)
sum(exclude)
View(data_wide)
data_wide$sum_time_listening
data_wide$sum_time_listening[data_wide$condition_binary == 1]
nrow(data_wide[data_wide$condition_binary == 1,])
nrow(data_wide[data_wide$condition_binary == 1 & data_wide$sum_time_listening < 128,])
nrow(data_wide[data_wide$condition_binary == 1 & data_wide$sum_time_listening < 78,])
setwd("C:/Users/Nanda/Desktop/threats/results - Copy")
figures_path <- "../figures"
showIndRuns <- 1
probabilities <- seq(0.1, 0.9, by = 0.2)
threats <- c(0,5,10,15,20,25,30)
# Ensure the figures_path exists or create it
if (!dir.exists(figures_path)) {
dir.create(figures_path)
}
for (probability in probabilities) {
png(filename = paste(figures_path, sprintf("/contribution_strategies_p%g.png", probability), sep = ""), width = 800, height = 600)
par(mfrow = c(1,2), cex.lab = 1, cex.axis = 1, lend = 1, las = 1)
x <- 0:6 * 5
coop <- vector()
Cs <- vector()
Ds <- vector()
Os <- vector()
coopcoop <- vector()
# Plot for cooperation strategies
plot(x, x*0, type = 'n', ylim = c(0,1),
xlab = 'Threat level \u03C4', ylab = 'Long term average pop. proportion',
main = paste('Contribution Strategies (p =', probability, ')'))
for (threat in threats){
CC <- DD <- OO <- numeric()
for (repl in 1:3){
na <- paste('contProps_test2PG_b3.0c1.0l0.5rho1.5i1e0mu0.01death0.1im1bP30tau', threat, '.0p', probability, 'repl', repl, '.0.txt', sep = '')
a <- if(file.exists(na)) {
read.table(na, header = TRUE, sep = ',')
}else data.frame(C=NA, D=NA, Oc=NA, Od=NA)
a$O <- a$Oc + a$Od
if(showIndRuns == 1 && nrow(a) > 0){
points(threat - 1 + runif(1) * 2, mean(a$C),  col = 'black', pch = 24, bg = 'blue', cex = 0.5)
points(threat - 1 + runif(1) * 2, mean(a$D),  col = 'black', pch = 25, bg = 'red', cex = 0.5)
points(threat - 1 + runif(1) * 2, mean(a$O),  col = 'black', pch = 23, bg = 'purple', cex = 0.5)
}
CC <- c(CC, mean(a$C, na.rm = TRUE))
DD <- c(DD, mean(a$D, na.rm = TRUE))
OO <- c(OO, mean(a$O, na.rm = TRUE))
}
Cs <- c(Cs, mean(CC, na.rm = TRUE))
Ds <- c(Ds, mean(DD, na.rm = TRUE))
Os <- c(Os, mean(OO, na.rm = TRUE))
}
lines(x, Cs, lty = 2, col = 'blue')
points(x, Cs, pch = 24, bg = 'blue', col = 'black')
lines(x, Ds, lty = 2, col = 'red')
points(x, Ds, pch = 25, bg = 'red', col = 'black')
lines(x, Os, lty = 2, col = 'purple')
points(x, Os, pch = 23, bg = 'purple', col = 'black')
legend('topleft', c('C', 'D', 'O'), lty = c(2,2,2),
col = c('black'), cex = c(1,1,1),
pch = c(24, 25, 23), pt.bg = c('blue', 'red', 'purple'))
# Calculate and plot cooperation percentage
for (threat in threats){
coopcoop <- numeric() # Reset for each threat level
for (repl in 1:3){
na <- paste('stats_test2PG_b3.0c1.0l0.5rho1.5i1e0mu0.01death0.1im1bP30tau', threat, '.0p', probability, 'repl', repl, '.0.txt', sep = '')
if (file.exists(na)){
a <- read.table(na, header = TRUE, sep = ',')
coopperc <- mean(a$coopPerc, na.rm = TRUE)
coopcoop <- c(coopcoop, coopperc)
if(showIndRuns == 1){
points(threat - 1 + runif(1) * 2, coopperc, pch = 16, col = 'black', cex = 0.5)
}
}
}
coop <- c(coop, mean(coopcoop, na.rm = TRUE))
}
lines(x, coop, lty = 3, col = 'black')
points(x, coop, pch = 19, col = 'black', cex = 1.5)
# Add coop% legend entry
legend('topleft', c('C', 'D', 'O', '%Coop'), lty = c(2,2,2,3),
col = c('black'), cex = c(1,1,1,1),
pch = c(24, 25, 23, 19), pt.bg = c('blue', 'red', 'purple', NA))
# This prepares for the punishment strategies plot
Rs <- As <- Ss <- Ns <- numeric()
Rs <- As <- Ss <- Ns <- numeric()
# Plot for punishment strategies
plot(x, x*0, type = 'n', ylim = c(0,1),
xlab = 'Threat level \u03C4', ylab = '', main = paste('Punishment Strategies (p =', probability, ')'))
for (threat in threats){
RR <- AA <- SS <- NN <- numeric()
for (repl in 1:3){
na <- paste('punProps_test2PG_b3.0c1.0l0.5rho1.5i1e0mu0.01death0.1im1bP30tau', threat, '.0p', probability, 'repl', repl, '.0.txt', sep = '')
a <- if(file.exists(na)) read.table(na, header = TRUE, sep = ',') else data.frame(R=NA, A=NA, S=NA, N=NA)
if(showIndRuns == 1 && nrow(a) > 0){
points(threat - 1 + runif(1) * 2, mean(a$R), bg = 'forestgreen', pch = 24, col = 'black', cex = 0.5)
points(threat - 1 + runif(1) * 2, mean(a$N), bg = 'deepskyblue', pch = 22, col = 'black', cex = 0.5)
points(threat - 1 + runif(1) * 2, mean(a$A), bg = 'darkorange', pch = 23, col = 'black', cex = 0.5)
points(threat - 1 + runif(1) * 2, mean(a$S), bg = 'violet', pch = 25, col = 'black', cex = 0.5)
}
RR <- c(RR, mean(a$R, na.rm = TRUE))
AA <- c(AA, mean(a$A, na.rm = TRUE))
SS <- c(SS, mean(a$S, na.rm = TRUE))
NN <- c(NN, mean(a$N, na.rm = TRUE))
}
Rs <- c(Rs, mean(RR, na.rm = TRUE))
As <- c(As, mean(AA, na.rm = TRUE))
Ss <- c(Ss, mean(SS, na.rm = TRUE))
Ns <- c(Ns, mean(NN, na.rm = TRUE))
}
lines(x, Rs, col = 'forestgreen', lty = 2)
points(x, Rs, pch = 24, bg = 'forestgreen', col = 'black')
lines(x, Ns, lty = 2, col = 'deepskyblue')
points(x, Ns, pch = 22, bg = 'deepskyblue', col = 'black')
lines(x, As, lty = 2, col = 'darkorange')
points(x, As, pch = 25, bg = 'darkorange', col = 'black')
lines(x, Ss, lty = 2, col = 'violet')
points(x, Ss, pch = 23, bg = 'violet', col = 'black')
legend('topleft', c('R', 'N', 'A', 'S'), lty = c(2,2,2,2),
col = c('forestgreen', 'deepskyblue', 'darkorange', 'violet'),
pch = c(24, 22, 23, 25), pt.bg = c('forestgreen', 'deepskyblue', 'darkorange', 'violet'))
dev.off()
}
plots <- list()
for (i in 1:length(probabilities)){
probability <- probabilities[i]
plots[[i]] <- magick::image_read(paste('../figures/contribution_strategies_p', probability, '.png', sep = ''))
}
row1 <- magick::image_append(c(plots[[1]], plots[[2]], plots[[3]]))
row2 <- magick::image_append(c(plots[[4]],plots[[5]]))
final_plot <- magick::image_append(c(row1, row2),stack = T)
x_pos <- 5
y_pos <- 5
x_increment <- 800
y_increment <- 600
# Annotating letters a-e with a loop
letters <- c("a", "b", "c", "d", "e")
for (i in 1:length(probabilities)) {
# Calculate position
posX <- x_pos + ((i - 1) %% 3) * x_increment
posY <- y_pos + ((i - 1) %/% 3) * y_increment
location_str <- paste0("+", posX, "+", posY)
final_plot <- magick::image_annotate(final_plot, letters[i], location = location_str, size = 50, color = "black")
}
magick::image_write(final_plot, "../figures/composite_plot.png")
